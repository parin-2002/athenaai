from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import RetrievalQA
from modules.prompt_templates import PromptTemplates
from langchain.chains.summarize import load_summarize_chain
from langchain.chains import LLMChain, SequentialChain

class QuestionAnswerChain:
    def __init__(self, model_name="gemini-pro", temperature=0.1):
        """
        Initialize the QuestionAnswerChain instance.

        Args:
            model_name (str): Name of the OpenAI chat model.
            temperature (float): Temperature parameter for model sampling.
        """
        self.model_name=model_name
        if model_name=="gpt-3.5-turbo-1106":
            self.model = ChatOpenAI(model=model_name, temperature=temperature)
        else:
            self.model = ChatGoogleGenerativeAI(model=model_name, temperature=temperature)
        

    def create_qa_chain(self, retriever, return_source_documents=True):
        """
        Create the Question-Answer chain.

        Args:
            retriever: Retriever for the QA chain.
            return_source_documents (bool): Whether to return source documents in the QA chain.
        """
        question_answer_template = PromptTemplates.question_answer_template()
        self.qa_chain = RetrievalQA.from_chain_type(
            self.model,
            retriever=retriever,
            return_source_documents=return_source_documents,
            chain_type_kwargs={"prompt": question_answer_template}
        )

    def answer_question(self, question):
        """
        Answer a question using the Question-Answer chain.

        Args:
            question (str): The question to answer.

        Returns:
            str: The answer generated by the model.
        """
        if self.qa_chain is None:
            raise ValueError("Question-Answer chain has not been created. Please call create_qa_chain() method first.")
        
        return self.qa_chain.invoke(question)
    
    def ensemble_retriever(self, ensemble_retriever):
        """
        Create a Question-Answer chain using the ensemble retriever.

        Args:
            ensemble_retriever: The ensemble retriever for the QA chain.
        """
        question_answer_template = PromptTemplates.question_answer_template()
        self.ensemble_retriever_qa_chain = RetrievalQA.from_chain_type(
            self.model,
            retriever=ensemble_retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": question_answer_template}
        )
        
    def get_answer(self, question):
        """
        Get an answer using the ensemble retriever QA chain.

        Args:
            question (str): The question to answer.

        Returns:
            str: The answer generated by the model.
        """
        if self.ensemble_retriever_qa_chain is None:
            raise ValueError("Ensemble retriever QA chain has not been created. Please call ensemble_retriever() method first.")
        
        return self.ensemble_retriever_qa_chain.invoke(question)

    def create_map_reduce_chain(self):
        """
        Create a map-reduce chain for summarization.
        """
        map_prompt_template = PromptTemplates.chunks_summary_prompt_template()
        combine_prompt_template = PromptTemplates.final_combine_summary_prompt_template()

        self.map_reduce_chain = load_summarize_chain(
            llm=self.model,
            chain_type='map_reduce',
            map_prompt=map_prompt_template, 
            combine_prompt=combine_prompt_template,
            verbose=False
        )
    
    def summarize_text_map_reduce(self, chunks):
        """
        Run the map-reduce summarization chain on the provided chunks.

        Args:
            chunks (list): List of text chunks to summarize.

        Returns:
            str: The combined summary of the chunks.
        """
        if self.map_reduce_chain is None:
            raise ValueError("Map-reduce summarization chain has not been created. Please call create_map_reduce_chain() method first.")
        
        return self.map_reduce_chain.invoke(chunks)
    
    def create_refinement_chain(self):
        """
        Create a refinement chain for summarization.
        """
        self.refinement_chain = load_summarize_chain(
            llm=self.model,
            chain_type='refine',
            verbose=True
        )

    def refine_summary(self, chunks):
        """
        Run the refinement chain on the provided chunks.

        Args:
            chunks (list): List of text chunks to refine.

        Returns:
            str: The refined summary of the chunks.
        """
        if self.refinement_chain is None:
            raise ValueError("Refinement summarization chain has not been created. Please call create_refinement_chain() method first.")
        
        return self.refinement_chain.invoke(chunks)
    
    def create_generate_evaluate_mcq_chain(self):
        """
        Create a combined chain for generating and evaluating a quiz.
        """
        quiz_chain = LLMChain(llm=self.model, prompt=PromptTemplates.quiz_generation_prompt_template(), output_key="quiz", verbose=True)
        review_chain = LLMChain(llm=self.model, prompt=PromptTemplates.quiz_evaluation_prompt_template(), output_key="review", verbose=True)

        self.generate_evaluate_chain = SequentialChain(
            chains=[quiz_chain, review_chain],
            input_variables=["text", "number", "subject", "tone", "response_json"],
            output_variables=["quiz", "review"],
            verbose=True
        )

    def generate_and_evaluate_quiz(self, text, number, subject, tone, response_json):
        """
        Generate and evaluate a quiz using the combined chain.

        Args:
            text (str): The text to generate quiz from.
            number (int): Number of questions in the quiz.
            subject (str): Subject of the quiz.
            tone (str): Tone of the quiz.
            response_json (str): JSON format for responses.

        Returns:
            dict: Dictionary containing generated quiz and its evaluation.
        """
        if self.generate_evaluate_chain is None:
            raise ValueError("Generate-evaluate chain has not been created. Please call create_generate_evaluate_chain() method first.")

        return self.generate_evaluate_chain({'text': text, 'number': number, 'subject': subject, 'tone': tone, 'response_json': response_json})

# Example usage:
# question_answer_chain = QuestionAnswerChain()
# question_answer_chain.create_qa_chain(retriever=base_retriever)
# question = "What is the capital of France?"
# answer = question_answer_chain.answer_question(question)
# print(answer)
